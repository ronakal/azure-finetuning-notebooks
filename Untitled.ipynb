{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ff70dc-38e7-4bfc-a92b-92d9396fcf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n",
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open('training_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open('validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b10149-0717-4bcc-9dc5-5afecf9e9a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 46, 59\n",
      "mean / median: 49.8, 48.5\n",
      "p5 / p95: 46.0, 53.599999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 13, 28\n",
      "mean / median: 16.5, 14.0\n",
      "p5 / p95: 13.0, 19.9\n",
      "**************************************************\n",
      "Processing file: validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 41, 64\n",
      "mean / median: 48.9, 47.0\n",
      "p5 / p95: 43.7, 54.099999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 8, 29\n",
      "mean / median: 15.0, 12.5\n",
      "p5 / p95: 10.7, 19.999999999999996\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc259456-b27e-495c-8d6c-46136442d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-b6eb9f3ddcb6478a80322f20030a20ee\n",
      "Validation file ID: file-0d8c82af0cb84e358bfbda28517f8211\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Read Azure env vars\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "if not endpoint or not api_key:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing env vars. \"\n",
    "        f\"AZURE_OPENAI_ENDPOINT={endpoint}, AZURE_OPENAI_API_KEY={api_key}\"\n",
    "    )\n",
    "\n",
    "# 2) IMPORTANT: add /openai/v1/ to the Azure endpoint\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    ")\n",
    "\n",
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\"\n",
    "\n",
    "# 3) Check files exist\n",
    "for f in (training_file_name, validation_file_name):\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"File not found: {f}\")\n",
    "\n",
    "# 4) Upload training file\n",
    "with open(training_file_name, \"rb\") as tf:\n",
    "    training_response = client.files.create(\n",
    "        file=tf,\n",
    "        purpose=\"fine-tune\",\n",
    "    )\n",
    "training_file_id = training_response.id\n",
    "\n",
    "# 5) Upload validation file\n",
    "with open(validation_file_name, \"rb\") as vf:\n",
    "    validation_response = client.files.create(\n",
    "        file=vf,\n",
    "        purpose=\"fine-tune\",\n",
    "    )\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf9d314-b6cf-431d-84e8-78e631c209be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-6d59d77b6f8c433ea94efb87b3f54c20\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-6d59d77b6f8c433ea94efb87b3f54c20\",\n",
      "  \"created_at\": 1764907871,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1.0,\n",
      "    \"n_epochs\": -1\n",
      "  },\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 1744545913,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-b6eb9f3ddcb6478a80322f20030a20ee\",\n",
      "  \"validation_file\": \"file-0d8c82af0cb84e358bfbda28517f8211\",\n",
      "  \"estimated_finish\": 1764910525,\n",
      "  \"integrations\": null,\n",
      "  \"metadata\": null,\n",
      "  \"method\": null,\n",
      "  \"trainingType\": \"standard\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Azure fine-tunable model id\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4691585-79c8-4752-af62-3718b300c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-6d59d77b6f8c433ea94efb87b3f54c20\n",
      "Status: running\n",
      "FineTuningJob(id='ftjob-6d59d77b6f8c433ea94efb87b3f54c20', created_at=1764907871, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=-1, learning_rate_multiplier=1.0, n_epochs=-1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id=None, result_files=None, seed=1744545913, status='running', trained_tokens=None, training_file='file-b6eb9f3ddcb6478a80322f20030a20ee', validation_file='file-0d8c82af0cb84e358bfbda28517f8211', estimated_finish=1764910525, integrations=None, metadata=None, method=None, trainingType='standard')\n"
     ]
    }
   ],
   "source": [
    "  response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f268d8-0d06-47cc-ab14-0366183ce8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status =response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6dacd-a992-4f1a-806a-e75ab3ab0361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637a2544-6f86-4f33-a447-930d6647410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-6d59d77b6f8c433ea94efb87b3f54c20', created_at=1764907871, error=None, fine_tuned_model='gpt-4o-mini-2024-07-18.ft-6d59d77b6f8c433ea94efb87b3f54c20', finished_at=1764910748, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.0, n_epochs=10), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id=None, result_files=['file-bec71888dbb44dbb828b2f9d1dc4eef0'], seed=1744545913, status='succeeded', trained_tokens=6710, training_file='file-b6eb9f3ddcb6478a80322f20030a20ee', validation_file='file-0d8c82af0cb84e358bfbda28517f8211', estimated_finish=1764909507, integrations=None, metadata=None, method=None, trainingType='standard')\n"
     ]
    }
   ],
   "source": [
    "#Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response)\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed142cda-9f43-41a6-8831-54cc8fbdbf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914dec13-2311-4e95-987b-16934567a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/2ec71f61-82f6-4857-a8ce-3dcf56061b9c/resourceGroups/ResourceGroup1/providers/Microsoft.CognitiveServices/accounts/AzureOpenAI-Finetune57399805/deployments/gpt-4o-mini-2024-07-18-ft', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-4o-mini-2024-07-18-ft', 'sku': {'name': 'standard', 'capacity': 1}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4o-mini-2024-07-18.ft-6d59d77b6f8c433ea94efb87b3f54c20', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'capabilities': {'area': 'US', 'chatCompletion': 'true', 'jsonObjectResponse': 'true', 'maxContextToken': '128000', 'maxOutputToken': '16384', 'assistants': 'true', 'responses': 'true', 'agentsV2': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 1}, {'key': 'token', 'renewalPeriod': 60, 'count': 1000}]}, 'systemData': {'createdBy': 'Depth-57399805@LODSPRODMCA.onmicrosoft.com', 'createdByType': 'User', 'createdAt': '2025-12-05T05:50:57.8328236Z', 'lastModifiedBy': 'Depth-57399805@LODSPRODMCA.onmicrosoft.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2025-12-05T05:50:57.8328236Z'}, 'etag': '\"d04b5d03-7fb2-4584-a477-f63acf017a95\"'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6InJ0c0ZULWItN0x1WTdEVlllU05LY0lKN1ZuYyIsImtpZCI6InJ0c0ZULWItN0x1WTdEVlllU05LY0lKN1ZuYyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC80Y2ZlMzcyYS0zN2E0LTQ0ZjgtOTFiMi01ZmFmMzQyNTNjNjIvIiwiaWF0IjoxNzY0OTA4MjkyLCJuYmYiOjE3NjQ5MDgyOTIsImV4cCI6MTc2NDkxMzg0OCwiYWNyIjoiMSIsImFjcnMiOlsicDEiXSwiYWlvIjoiQWVRQUcvOGFBQUFBam9lU3BoOXV1djFlcUdNN0FwbmJ2ajhvZjhpUDVsSnVyNVdMYXhDUE5adU9SOG56SENQemQySDJGSytYT1NEWkthbFR3d1dOMDhwR3preGo3Q0h4SzE1S2NSTWdFOVdxL201QkJMK2ZZd3hGZkhFMmhCVW9OQ0RvV0ZYREVnV21uSEdGNkNTQVp3TENOMUdwUG9sK09zejZucW1KTUFRcVR2MWRncVg5UUdBUnppbXEveFNnb1hBT2VZTnBMTFBCdWZ4aHZZR3lYNDUrRkZjUHgzMkFINFp4YThraWFXOUZ2d25vUjF2aGVEeklSNlRjb1dtVHk5OEhUVXFIODM4MjJ0ck1LRWo0RDVoSERHNW1Oby90ZWJBUEQzRVU5UFNidFIwZ1VtOXMvNVU9IiwiYW1yIjpbInRhcCIsIm1mYSJdLCJhcHBpZCI6ImI2NzdjMjkwLWNmNGItNGE4ZS1hNjBlLTkxYmE2NTBhNGFiZSIsImFwcGlkYWNyIjoiMCIsImdyb3VwcyI6WyI5Y2NjZTNkZC00OTRjLTRlYjItYjJjYS00N2JkYmIwZTk1ODQiXSwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiMTY4LjI0NS4yMDMuMjQ2IiwibmFtZSI6IkRlcHRoLTU3Mzk5ODA1Iiwib2lkIjoiZmFmMWU1YzUtYmZhMi00ZjQzLWI5ODYtM2RlNzBiYTZiZjNhIiwicHVpZCI6IjEwMDMyMDA1NjE4NTc5N0EiLCJyaCI6IjEuQVZBQUtqZi1US1EzLUVTUnNsLXZOQ1U4WWtaSWYza0F1dGRQdWtQYXdmajJNQk5RQUVaUUFBLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInNpZCI6IjAwYjdlNjM5LTRmYzAtYTI0OS05OTIzLWY2ZDA1ZWVkNzBhNSIsInN1YiI6ImNSUVEwSEFDY2FhdUZNcGdKeHIxVld2aG1wNDJmd2lqRS1DQ3d4RG5vM2ciLCJ0aWQiOiI0Y2ZlMzcyYS0zN2E0LTQ0ZjgtOTFiMi01ZmFmMzQyNTNjNjIiLCJ1bmlxdWVfbmFtZSI6IkRlcHRoLTU3Mzk5ODA1QExPRFNQUk9ETUNBLm9ubWljcm9zb2Z0LmNvbSIsInVwbiI6IkRlcHRoLTU3Mzk5ODA1QExPRFNQUk9ETUNBLm9ubWljcm9zb2Z0LmNvbSIsInV0aSI6Ik9VZGN1OEVwNUVTeXlwWU9CR3dKQUEiLCJ2ZXIiOiIxLjAiLCJ3aWRzIjpbImI3OWZiZjRkLTNlZjktNDY4OS04MTQzLTc2YjE5NGU4NTUwOSJdLCJ4bXNfYWN0X2ZjdCI6IjMgNSIsInhtc19mdGQiOiJJZjZVTkhHaWlUYlRTNG1UNkVkck9VUV9ITnFZRFpUX1pqWTNSQW1zb0JBQmRYTjNaWE4wTXkxa2MyMXoiLCJ4bXNfaWRyZWwiOiIxIDE4IiwieG1zX3N1Yl9mY3QiOiIxNCAzIiwieG1zX3RjZHQiOjE2Mjc0NzkwODR9.eJ17XdXOAST6lF-7Jr8N8JXrC--sLiEuWge1SCNz9R5etbWmKBaMM0dPSCjNVJZWfEEd0b0kO0Xp8eNxKYWpFPK7QgdXlSIJz4L6z0PeXbQWUC_wTm2ptT0CLKGnRBCOMFTISANWaY4R0RmHKhiy_JaXbc6GrDr_jdpzTiA6Il8xtxAjBwH2Mrp9aoIZQa4sAGJVlY5x_DqAiZ4lvW3CDCnDz9s8g6bgaE1lsYBTLeIHE4ibGT1i7ejRkBDXnIaQdYA0nP7V84yJlBrnq6OG1Sh2zbmwgxVXOTKscBC39NlstWPQYFDegChTkJknuZhodA3Ms6wCce8cGRK8GSkzsg\"\n",
    "subscription = \"2ec71f61-82f6-4857-a8ce-3dcf56061b9c\"\n",
    "resource_group = \"ResourceGroup1\"\n",
    "resource_name = \"AzureOpenAI-Finetune57399805\"\n",
    "model_deployment_name = \"gpt-4o-mini-2024-07-18-ft\" # Custom deployment name you chose for your fine-tuning model\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"}\n",
    "deploy_headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-4o-mini-2024-07-18.ft-6d59d77b6f8c433ea94efb87b3f54c20\", #retrieve this value from the previous call, it will look like gpt-4o-mini-2024-07-18.ft-0e208cf33a6a466994aff31a08aba678\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9a884-c143-4130-a3c8-1bb561057635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
