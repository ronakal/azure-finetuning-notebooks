{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ff70dc-38e7-4bfc-a92b-92d9396fcf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n",
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open('training_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open('validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b10149-0717-4bcc-9dc5-5afecf9e9a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 46, 59\n",
      "mean / median: 49.8, 48.5\n",
      "p5 / p95: 46.0, 53.599999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 13, 28\n",
      "mean / median: 16.5, 14.0\n",
      "p5 / p95: 13.0, 19.9\n",
      "**************************************************\n",
      "Processing file: validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 41, 64\n",
      "mean / median: 48.9, 47.0\n",
      "p5 / p95: 43.7, 54.099999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 8, 29\n",
      "mean / median: 15.0, 12.5\n",
      "p5 / p95: 10.7, 19.999999999999996\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc259456-b27e-495c-8d6c-46136442d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-b6eb9f3ddcb6478a80322f20030a20ee\n",
      "Validation file ID: file-0d8c82af0cb84e358bfbda28517f8211\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Read Azure env vars\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "if not endpoint or not api_key:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing env vars. \"\n",
    "        f\"AZURE_OPENAI_ENDPOINT={endpoint}, AZURE_OPENAI_API_KEY={api_key}\"\n",
    "    )\n",
    "\n",
    "# 2) IMPORTANT: add /openai/v1/ to the Azure endpoint\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    ")\n",
    "\n",
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\"\n",
    "\n",
    "# 3) Check files exist\n",
    "for f in (training_file_name, validation_file_name):\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"File not found: {f}\")\n",
    "\n",
    "# 4) Upload training file\n",
    "with open(training_file_name, \"rb\") as tf:\n",
    "    training_response = client.files.create(\n",
    "        file=tf,\n",
    "        purpose=\"fine-tune\",\n",
    "    )\n",
    "training_file_id = training_response.id\n",
    "\n",
    "# 5) Upload validation file\n",
    "with open(validation_file_name, \"rb\") as vf:\n",
    "    validation_response = client.files.create(\n",
    "        file=vf,\n",
    "        purpose=\"fine-tune\",\n",
    "    )\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf9d314-b6cf-431d-84e8-78e631c209be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-6d59d77b6f8c433ea94efb87b3f54c20\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-6d59d77b6f8c433ea94efb87b3f54c20\",\n",
      "  \"created_at\": 1764907871,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1.0,\n",
      "    \"n_epochs\": -1\n",
      "  },\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 1744545913,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-b6eb9f3ddcb6478a80322f20030a20ee\",\n",
      "  \"validation_file\": \"file-0d8c82af0cb84e358bfbda28517f8211\",\n",
      "  \"estimated_finish\": 1764910525,\n",
      "  \"integrations\": null,\n",
      "  \"metadata\": null,\n",
      "  \"method\": null,\n",
      "  \"trainingType\": \"standard\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Azure fine-tunable model id\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4691585-79c8-4752-af62-3718b300c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-6d59d77b6f8c433ea94efb87b3f54c20\n",
      "Status: running\n",
      "FineTuningJob(id='ftjob-6d59d77b6f8c433ea94efb87b3f54c20', created_at=1764907871, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=-1, learning_rate_multiplier=1.0, n_epochs=-1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id=None, result_files=None, seed=1744545913, status='running', trained_tokens=None, training_file='file-b6eb9f3ddcb6478a80322f20030a20ee', validation_file='file-0d8c82af0cb84e358bfbda28517f8211', estimated_finish=1764910525, integrations=None, metadata=None, method=None, trainingType='standard')\n"
     ]
    }
   ],
   "source": [
    "  response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f268d8-0d06-47cc-ab14-0366183ce8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status =response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6dacd-a992-4f1a-806a-e75ab3ab0361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "637a2544-6f86-4f33-a447-930d6647410f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Retrieve fine_tuned_model name\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[0;32m      6\u001b[0m fine_tuned_model \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mfine_tuned_model\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\openai\\resources\\fine_tuning\\jobs\\jobs.py:207\u001b[0m, in \u001b[0;36mJobs.retrieve\u001b[1;34m(self, fine_tuning_job_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fine_tuning_job_id:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `fine_tuning_job_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tuning_job_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfine_tuning_job_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1205\u001b[0m, in \u001b[0;36mSyncAPIClient.get\u001b[1;34m(self, path, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1202\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[1;32m-> 1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "#Retrieve fine_tuned_model name\n",
    "\n",
    "response = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response)\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed142cda-9f43-41a6-8831-54cc8fbdbf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914dec13-2311-4e95-987b-16934567a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Deploy fine-tuned model\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "token = os.getenv(\"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6InJ0c0ZULWItN0x1WTdEVlllU05LY0lKN1ZuYyIsImtpZCI6InJ0c0ZULWItN0x1WTdEVlllU05LY0lKN1ZuYyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC80Y2ZlMzcyYS0zN2E0LTQ0ZjgtOTFiMi01ZmFmMzQyNTNjNjIvIiwiaWF0IjoxNzY0OTA4MjkyLCJuYmYiOjE3NjQ5MDgyOTIsImV4cCI6MTc2NDkxMzg0OCwiYWNyIjoiMSIsImFjcnMiOlsicDEiXSwiYWlvIjoiQWVRQUcvOGFBQUFBam9lU3BoOXV1djFlcUdNN0FwbmJ2ajhvZjhpUDVsSnVyNVdMYXhDUE5adU9SOG56SENQemQySDJGSytYT1NEWkthbFR3d1dOMDhwR3preGo3Q0h4SzE1S2NSTWdFOVdxL201QkJMK2ZZd3hGZkhFMmhCVW9OQ0RvV0ZYREVnV21uSEdGNkNTQVp3TENOMUdwUG9sK09zejZucW1KTUFRcVR2MWRncVg5UUdBUnppbXEveFNnb1hBT2VZTnBMTFBCdWZ4aHZZR3lYNDUrRkZjUHgzMkFINFp4YThraWFXOUZ2d25vUjF2aGVEeklSNlRjb1dtVHk5OEhUVXFIODM4MjJ0ck1LRWo0RDVoSERHNW1Oby90ZWJBUEQzRVU5UFNidFIwZ1VtOXMvNVU9IiwiYW1yIjpbInRhcCIsIm1mYSJdLCJhcHBpZCI6ImI2NzdjMjkwLWNmNGItNGE4ZS1hNjBlLTkxYmE2NTBhNGFiZSIsImFwcGlkYWNyIjoiMCIsImdyb3VwcyI6WyI5Y2NjZTNkZC00OTRjLTRlYjItYjJjYS00N2JkYmIwZTk1ODQiXSwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiMTY4LjI0NS4yMDMuMjQ2IiwibmFtZSI6IkRlcHRoLTU3Mzk5ODA1Iiwib2lkIjoiZmFmMWU1YzUtYmZhMi00ZjQzLWI5ODYtM2RlNzBiYTZiZjNhIiwicHVpZCI6IjEwMDMyMDA1NjE4NTc5N0EiLCJyaCI6IjEuQVZBQUtqZi1US1EzLUVTUnNsLXZOQ1U4WWtaSWYza0F1dGRQdWtQYXdmajJNQk5RQUVaUUFBLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInNpZCI6IjAwYjdlNjM5LTRmYzAtYTI0OS05OTIzLWY2ZDA1ZWVkNzBhNSIsInN1YiI6ImNSUVEwSEFDY2FhdUZNcGdKeHIxVld2aG1wNDJmd2lqRS1DQ3d4RG5vM2ciLCJ0aWQiOiI0Y2ZlMzcyYS0zN2E0LTQ0ZjgtOTFiMi01ZmFmMzQyNTNjNjIiLCJ1bmlxdWVfbmFtZSI6IkRlcHRoLTU3Mzk5ODA1QExPRFNQUk9ETUNBLm9ubWljcm9zb2Z0LmNvbSIsInVwbiI6IkRlcHRoLTU3Mzk5ODA1QExPRFNQUk9ETUNBLm9ubWljcm9zb2Z0LmNvbSIsInV0aSI6Ik9VZGN1OEVwNUVTeXlwWU9CR3dKQUEiLCJ2ZXIiOiIxLjAiLCJ3aWRzIjpbImI3OWZiZjRkLTNlZjktNDY4OS04MTQzLTc2YjE5NGU4NTUwOSJdLCJ4bXNfYWN0X2ZjdCI6IjMgNSIsInhtc19mdGQiOiJJZjZVTkhHaWlUYlRTNG1UNkVkck9VUV9ITnFZRFpUX1pqWTNSQW1zb0JBQmRYTjNaWE4wTXkxa2MyMXoiLCJ4bXNfaWRyZWwiOiIxIDE4IiwieG1zX3N1Yl9mY3QiOiIxNCAzIiwieG1zX3RjZHQiOjE2Mjc0NzkwODR9.eJ17XdXOAST6lF-7Jr8N8JXrC--sLiEuWge1SCNz9R5etbWmKBaMM0dPSCjNVJZWfEEd0b0kO0Xp8eNxKYWpFPK7QgdXlSIJz4L6z0PeXbQWUC_wTm2ptT0CLKGnRBCOMFTISANWaY4R0RmHKhiy_JaXbc6GrDr_jdpzTiA6Il8xtxAjBwH2Mrp9aoIZQa4sAGJVlY5x_DqAiZ4lvW3CDCnDz9s8g6bgaE1lsYBTLeIHE4ibGT1i7ejRkBDXnIaQdYA0nP7V84yJlBrnq6OG1Sh2zbmwgxVXOTKscBC39NlstWPQYFDegChTkJknuZhodA3Ms6wCce8cGRK8GSkzsg\")\n",
    "subscription = \"2ec71f61-82f6-4857-a8ce-3dcf56061b9c\"\n",
    "resource_group = \"ResourceGroup1\"\n",
    "resource_name = \"AzureOpenAI-Finetune57399805\"\n",
    "model_deployment_name = \"gpt-4o-mini-2024-07-18-ft\" # Custom deployment name you chose for your fine-tuning model\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-4o-mini-2024-07-18.ftjob-6d59d77b6f8c433ea94efb87b3f54c20\", #retrieve this value from the previous call, it will look like gpt-4o-mini-2024-07-18.ft-0e208cf33a6a466994aff31a08aba678\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9a884-c143-4130-a3c8-1bb561057635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
